# Pipeline ETL pour Citymapper avec Apache Airflow

**Automatisation de l'acquisition et du traitement des donn√©es de location de v√©los et m√©t√©orologiques √† Paris**

---

## üèôÔ∏è **Contexte**

Vous √™tes ing√©nieur de donn√©es chez Citymapper, une application qui aide les utilisateurs √† planifier leurs d√©placements dans les grandes villes du monde. Vous travaillez avec l'√©quipe parisienne (bas√©e √† Londres) pour construire un pipeline ETL qui extrait les donn√©es de l'API et les charge dans une base de donn√©es Postgres. Ce pipeline permettra aux analystes de donn√©es d'analyser le trafic de location de v√©los √† Paris en tenant compte des conditions m√©t√©orologiques.

---

## üéØ **Objectif**

Construire un pipeline ETL avec Apache Airflow pour :

- **Extraire les donn√©es** : R√©cup√©rer les donn√©es m√©t√©orologiques et l'√©tat des stations de v√©los √† partir des API.
- **Transformer les donn√©es** : Convertir les donn√©es JSON en fichiers CSV adapt√©s √† la base de donn√©es Postgres.
- **Charger les donn√©es** : Ins√©rer les donn√©es transform√©es dans la base de donn√©es Postgres toutes les heures.

---

## üõ†Ô∏è **Technologies Utilis√©es**

- **Apache Airflow** : Pour l'orchestration des workflows et l'automatisation des pipelines de donn√©es.
- **Python** : Pour le d√©veloppement des scripts de traitement des donn√©es.
- **Pandas** : Pour la manipulation et l'analyse des donn√©es.
- **PostgreSQL** : Pour le stockage des donn√©es transform√©es.
- **AWS S3** : Pour le stockage interm√©diaire des fichiers de donn√©es.
- **WeatherBit API** : Pour l'acquisition des donn√©es m√©t√©orologiques.

---

## üìä **Pipeline de Donn√©es**

Le pipeline ETL comprendra deux branches principales :

1. **Branche M√©t√©o** :
   - R√©cup√©rer les donn√©es m√©t√©orologiques de Paris via l'API WeatherBit.
   - Transformer les donn√©es JSON en fichiers CSV.
   - Charger les donn√©es dans une table Postgres nomm√©e `weather_data`.

2. **Branche √âtat des Stations** :
   - R√©cup√©rer les donn√©es d'√©tat des stations de v√©los via l'API.
   - Transformer les donn√©es JSON en fichiers CSV.
   - Charger les donn√©es dans une table Postgres nomm√©e `station_status`.

---
![image](https://github.com/user-attachments/assets/384e9027-f50f-4c12-8c0d-f1374e6eef24)


